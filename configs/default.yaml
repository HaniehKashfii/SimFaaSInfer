# Default configuration for SimFaaSInfer

simulation:
  duration: 3600  # seconds
  warmup_duration: 300  # seconds
  random_seed: 42

workload:
  type: "poisson"  # poisson, trace, synthetic
  arrival_rate: 10  # requests per second
  num_requests: 1000
  prompt_length:
    distribution: "gamma"
    mean: 512
    std: 256
    min: 1
    max: 4096
  decode_length:
    distribution: "gamma"
    mean: 128
    std: 64
    min: 1
    max: 2048

cluster:
  num_replicas: 1
  gpu_type: "A100"  # A100, H100
  gpu_memory_gb: 80
  num_gpus_per_replica: 1

parallelization:
  tensor_parallel_size: 1
  pipeline_parallel_size: 1

scheduler:
  type: "vllm"  # vllm, orca, sarathi, fastertransformer
  max_batch_size: 256
  max_tokens_per_batch: 4096
  scheduling_policy: "fcfs"  # fcfs, priority

memory:
  kv_cache_dtype: "float16"
  reserved_memory_gb: 2.0

cold_start:
  enabled: true
  model_load_time: 30.0  # seconds
  initial_instances: 1

scaling:
  enabled: true
  min_instances: 1
  max_instances: 10
  scale_up_threshold: 0.8  # utilization
  scale_down_threshold: 0.2
  cooldown_period: 300  # seconds

cost:
  gpu_cost_per_hour:
    A100: 3.06  # Azure pricing
    H100: 5.12
  compute_cost: true
  idle_cost: true

metrics:
  collect_interval: 1.0  # seconds
  percentiles: [50, 90, 95, 99]

logging:
  level: "INFO"
  log_file: "simulation.log"
  console_output: true